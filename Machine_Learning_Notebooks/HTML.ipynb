{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45308f34-3f43-4e2e-addb-fb331c80e581",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "grades = [ 80, 90, 100, 35, 70]\n",
    "\n",
    "np.mean(grades)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4478d41b-d8ee-4862-9371-df45df4ba12d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A    2.0\n",
       "B    5.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6]})\n",
    "\n",
    "def mean(column):\n",
    "  return column.mean()\n",
    "\n",
    "df.apply(lambda x: x.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4059ffd0-da18-45d9-b731-94903923f8a2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A    2.0\n",
       "B    5.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.apply(mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9b41fcb4-5c32-4cce-b65e-7d332a433a32",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encountered a start tag: html\n",
      "Encountered a start tag: head\n",
      "Encountered a start tag: title\n",
      "Encountered some data  : This is a title\n",
      "Encountered an end tag : title\n",
      "Encountered an end tag : head\n"
     ]
    }
   ],
   "source": [
    "from html.parser import HTMLParser\n",
    "\n",
    "\n",
    "class MyHTMLParser(HTMLParser):\n",
    "    def handle_starttag(self, tag, attrs):\n",
    "        print(\"Encountered a start tag:\", tag)\n",
    "\n",
    "    def handle_endtag(self, tag):\n",
    "        print(\"Encountered an end tag :\", tag)\n",
    "\n",
    "    def handle_data(self, data):\n",
    "        print(\"Encountered some data  :\", data)\n",
    "        \n",
    "htmlString = '<html><head><title>This is a title</title></head>'\n",
    "'<body><h2> Test </h2><p>Hello world!</p></body></html>'\n",
    "\n",
    "parser = MyHTMLParser()\n",
    "parser.feed(htmlString)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8271e61-d5ab-4b3a-a4e7-f74ed8b2e7a9",
   "metadata": {},
   "source": [
    "## Beautiful Soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5e5f4f2a-b3b1-4299-b3cc-590988bb008c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib.request as urllib2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9bd361ad-d083-4cae-ac54-fe45ac40e1c5",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.0 Transitional//EN\"\\n\"http://www.w3.org/TR/REC-html40/transitional.dtd\">\\n<html>\\n<head>\\n<meta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\">\\n<title>Beautiful Soup: We called him Tortoise because he taught us.</title>\\n<link rev=\"made\" href=\"mailto:leonardr@segfault.org\">\\n<link rel=\"stylesheet\" type=\"text/css\" href=\"/nb/themes/Default/nb.css\">\\n<meta name=\"Description\" content=\"Beautiful Soup: a library designed for screen-scraping HTML and XML.\">\\n<meta name=\"generator\" content=\"Markov Approximation 1.4 (module: leonardr)\">\\n<meta name=\"author\" content=\"Leonard Richardson\">\\n</head>\\n<body bgcolor=\"white\" text=\"black\" link=\"blue\" vlink=\"660066\" alink=\"red\">\\n<style>\\n#tidelift { }\\n\\n#tidelift a {\\n border: 1px solid #666666;\\n margin-left: auto;\\n padding: 10px;\\n text-decoration: none;\\n}\\n\\n#tidelift .cta {\\n background: url(\"tidelift.svg\") no-repeat;\\n padding-left: 30px;\\n}\\n</style>\\t\\t   \\n\\n<img align=\"right\" src=\"10.1.jpg\" width=\"250\"><br />\\n\\n<p>[ <a href=\"#Download\">Download</a> | <a\\nhref=\"bs4/doc/\">Documentation</a> | <a href=\"#HallOfFame\">Hall of Fame</a> | <a href=\"enterprise.html\">For enterprise</a> | <a href=\"https://code.launchpad.net/beautifulsoup\">Source</a> | <a href=\"https://git.launchpad.net/beautifulsoup/tree/CHANGELOG\">Changelog</a> | <a href=\"https://groups.google.com/forum/?fromgroups#!forum/beautifulsoup\">Discussion group</a>  | <a href=\"zine/\">Zine</a> ]</p>\\n\\n<div align=\"center\">\\n\\n<a href=\"bs4/download/\"><h1>Beautiful Soup</h1></a>\\n\\n</div>\\n\\n<p>You didn\\'t write that awful page. You\\'re just trying to get some\\ndata out of it. Beautiful Soup is here to help. Since 2004, it\\'s been\\nsaving programmers hours or days of work on quick-turnaround\\nscreen scraping projects.</p>\\n\\n<p>Beautiful Soup is a Python library designed for quick turnaround\\nprojects like screen-scraping. Three features make it powerful:\\n\\n<ol>\\n\\n<li>Beautiful Soup provides a few simple methods and Pythonic idioms\\nfor navigating, searching, and modifying a parse tree: a toolkit for\\ndissecting a document and extracting what you need. It doesn\\'t take\\nmuch code to write an application\\n\\n<li>Beautiful Soup automatically converts incoming documents to\\nUnicode and outgoing documents to UTF-8. You don\\'t have to think\\nabout encodings, unless the document doesn\\'t specify an encoding and\\nBeautiful Soup can\\'t detect one. Then you just have to specify the\\noriginal encoding.\\n\\n<li>Beautiful Soup sits on top of popular Python parsers like <a\\nhref=\"http://lxml.de/\">lxml</a> and <a\\nhref=\"http://code.google.com/p/html5lib/\">html5lib</a>, allowing you\\nto try out different parsing strategies or trade speed for\\nflexibility.\\n\\n</ol>\\n\\n<p>Beautiful Soup parses anything you give it, and does the tree\\ntraversal stuff for you. You can tell it \"Find all the links\", or\\n\"Find all the links of class <tt>externalLink</tt>\", or \"Find all the\\nlinks whose urls match \"foo.com\", or \"Find the table heading that\\'s\\ngot bold text, then give me that text.\"\\n\\n<p>Valuable data that was once locked up in poorly-designed websites\\nis now within your reach. Projects that would have taken hours take\\nonly minutes with Beautiful Soup.\\n\\n<p>Interested? <a href=\"bs4/doc/\">Read more.</a>\\n\\n<h3>Getting and giving support</h3>\\n\\n<div id=\"tidelift\" align=\"center\">\\n<a href=\"https://tidelift.com/subscription/pkg/pypi-beautifulsoup4?utm_source=pypi-beautifulsoup4&utm_medium=referral&utm_campaign=enterprise\" target=\"_blank\">\\n <span class=\"cta\">\\n  Beautiful Soup for enterprise available via Tidelift\\n </span>\\n</a>\\n</div>\\n\\n<p>If you have questions, send them to <a\\nhref=\"https://groups.google.com/forum/?fromgroups#!forum/beautifulsoup\">the discussion\\ngroup</a>. If you find a bug, <a href=\"https://bugs.launchpad.net/beautifulsoup/\">file it on Launchpad</a>. If it\\'s a security vulnerability, report it confidentially through <a href=\"https://tidelift.com/security\">Tidelift</a>.</p>\\n\\n<p>If you use Beautiful Soup as part of your work, please consider a <a href=\"https://tidelift.com/subscription/pkg/pypi-beautifulsoup4?utm_source=pypi-beautifulsoup4&utm_medium=referral&utm_campaign=website\">Tidelift subscription</a>. This will support many of the free software projects your organization depends on, not just Beautiful Soup.\\n\\n\\n<p>If Beautiful Soup is useful to you on a personal level, you might like to read <a href=\"zine/\"><i>Tool Safety</i></a>, a short zine I wrote about what I learned about software development from working on Beautiful Soup. Thanks!</p>\\n</div>\\n\\n\\n<a name=\"Download\"><h2>Download Beautiful Soup</h2></a>\\n\\n<p>The current release is <a href=\"bs4/download/\">Beautiful Soup\\n4.12.3</a> (January 17, 2024). You can install Beautiful Soup 4 with\\n<code>pip install beautifulsoup4</code>.\\n\\n<p>In Debian and Ubuntu, Beautiful Soup is available as the\\n<code>python3-bs4</code> package. In Fedora it\\'s\\navailable as the <code>python3-beautifulsoup4</code> package.\\n\\n<p>Beautiful Soup is licensed under the MIT license, so you can also\\ndownload the tarball, drop the <code>bs4/</code> directory into almost\\nany Python application (or into your library path) and start using it\\nimmediately.\\n\\n<p>Beautiful Soup 4 is supported on Python versions 3.6 and\\ngreater. Support for Python 2 was discontinued on January 1, 2021&mdash;one\\nyear after the Python 2 sunsetting date.\\n\\n<h3>Beautiful Soup 3</h3>\\n\\n<p>Beautiful Soup 3 was the official release line of Beautiful Soup\\nfrom May 2006 to March 2012. It does not support Python 3 and was\\ndiscontinued or January 1, 2021&mdash;one year after the Python 2\\nsunsetting date. If you have any active projects using Beautiful Soup\\n3, you should migrate to Beautiful Soup 4 as part of your Python 3\\nconversion.\\n\\n<p><a\\nhref=\"http://www.crummy.com/software/BeautifulSoup/bs3/documentation.html\">Here\\'s\\nthe Beautiful Soup 3 documentation.</a>\\n\\n<p>The current and hopefully final release of Beautiful Soup 3 is <a\\nhref=\"download/3.x/BeautifulSoup-3.2.2.tar.gz\">3.2.2</a> (October 5,\\n2019). It\\'s the <code>BeautifulSoup</code> package on pip. It\\'s also\\navailable as <code>python-beautifulsoup</code> in Debian and Ubuntu,\\nand as <code>python-BeautifulSoup</code> in Fedora.\\n\\n<p>Once Beautiful Soup 3 is discontinued, these package names will be available for use by a more recent version of Beautiful Soup.\\n\\n<p>Beautiful Soup 3, like Beautiful Soup 4, is <a href=\"https://tidelift.com/subscription/pkg/pypi-beautifulsoup?utm_source=pypi-beautifulsoup&utm_medium=referral&utm_campaign=website\">supported through Tidelift</a>.</p>\\n\\n<a name=\"HallOfFame\"><h2>Hall of Fame</h2></a>\\n\\n<p>Over the years, Beautiful Soup has been used in hundreds of\\ndifferent projects. There\\'s no way I can list them all, but I want to\\nhighlight a few high-profile projects. Beautiful Soup isn\\'t what makes\\nthese projects interesting, but it did make their completion easier:\\n\\n<ul>\\n\\n<li><a\\n href=\"http://www.nytimes.com/2007/10/25/arts/design/25vide.html\">\"Movable\\n Type\"</a>, a work of digital art on display in the lobby of the New\\n York Times building, uses Beautiful Soup to scrape news feeds.\\n\\n<li>Jiabao Lin\\'s <a\\nhref=\"https://github.com/BlankerL/DXY-COVID-19-Crawler\">DXY-COVID-19-Crawler</a>\\nuses Beautiful Soup to scrape a Chinese medical site for information\\nabout COVID-19, making it easier for researchers to track the spread\\nof the virus. (Source: <a href=\"https://blog.tidelift.com/how-open-source-software-is-fighting-covid-19\">\"How open source software is fighting COVID-19\"</a>)\\n\\n<li>Reddit uses Beautiful Soup to <a\\nhref=\"https://github.com/reddit/reddit/blob/85f9cff3e2ab9bb8f19b96acd8da4ebacc079f04/r2/r2/lib/media.py\">parse\\na page that\\'s been linked to and find a representative image</a>.\\n\\n<li>Alexander Harrowell uses Beautiful Soup to <a\\n href=\"http://www.harrowell.org.uk/viktormap.html\">track the business\\n activities</a> of an arms merchant.\\n\\n<li>The developers of Python itself used Beautiful Soup to <a\\nhref=\"http://svn.python.org/view/tracker/importer/\">migrate the Python\\nbug tracker from Sourceforge to Roundup</a>.\\n\\n<li>The <a href=\"http://www2.ljworld.com/\">Lawrence Journal-World</a>\\nuses Beautiful Soup to <A\\nhref=\"http://www.b-list.org/weblog/2010/nov/02/news-done-broke/\">gather\\nstatewide election results</a>.\\n\\n<li>The <a href=\"http://esrl.noaa.gov/gsd/fab/\">NOAA\\'s Forecast\\nApplications Branch</a> uses Beautiful Soup in <a\\nhref=\"http://laps.noaa.gov/topograbber/\">TopoGrabber</a>, a script for\\ndownloading \"high resolution USGS datasets.\"\\n\\n</ul>\\n\\n<p>If you\\'ve used Beautiful Soup in a project you\\'d like me to know\\nabout, please do send email to me or <a\\nhref=\"http://groups.google.com/group/beautifulsoup/\">the discussion\\ngroup</a>.\\n\\n<h2>Development</h2>\\n\\n<p>Development happens at <a\\nhref=\"https://launchpad.net/beautifulsoup\">Launchpad</a>. You can <a\\nhref=\"https://code.launchpad.net/beautifulsoup/\">get the source\\ncode</a> or <a href=\"https://bugs.launchpad.net/beautifulsoup/\">file\\nbugs</a>.<hr><table><tr><td valign=\"top\">\\n<p>This document is part of Crummy, the webspace of <a href=\"/self/\">Leonard Richardson</a> (<a href=\"/self/contact.html\">contact information</a>). It was last modified on Wednesday, January 17 2024, 16:54:42 Nowhere Standard Time and last built on Monday, March 04 2024, 03:00:01 Nowhere Standard Time.</p><p><table class=\"licenseText\"><tr><td><a href=\"http://creativecommons.org/licenses/by-sa/2.0/\"><img border=\"0\" src=\"/nb//resources/img/somerights20.jpg\"></a></td><td valign=\"top\">Crummy is &copy; 1996-2024 Leonard Richardson. Unless otherwise noted, all text licensed under a <a href=\"http://creativecommons.org/licenses/by-sa/2.0/\">Creative Commons License</a>.</td></tr></table></span><!--<rdf:RDF xmlns=\"http://web.resource.org/cc/\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\"><Work rdf:about=\"http://www.crummy.com/\"><dc:title>Crummy: The Site</dc:title><dc:rights><Agent><dc:title>Crummy: the Site</dc:title></Agent></dc:rights><dc:format>text/html</dc:format><license rdf:resource=http://creativecommons.org/licenses/by-sa/2.0//></Work><License rdf:about=\"http://creativecommons.org/licenses/by-sa/2.0/\"></License></rdf:RDF>--></p></td><td valign=top><p><b>Document tree:</b>\\n<dl><dd><a href=\"http://www.crummy.com/\">http://www.crummy.com/</a><dl><dd><a href=\"http://www.crummy.com/software/\">software/</a><dl><dd><a href=\"http://www.crummy.com/software/BeautifulSoup/\">BeautifulSoup/</a></dl>\\n</dl>\\n</dl>\\n\\n\\nSite Search:\\n\\n<form method=\"get\" action=\"/search/\">\\n        <input type=\"text\" name=\"q\" maxlength=\"255\" value=\"\"></input>\\n        </form>\\n        </td>\\n\\n</tr>\\n\\n</table>\\n</body>\\n</html>\\n'\n"
     ]
    }
   ],
   "source": [
    "url = 'http://www.crummy.com/software/BeautifulSoup'\n",
    "source = urllib2.urlopen(url).read()\n",
    "print(source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90024396-957a-454a-81b7-f654941fd771",
   "metadata": {},
   "outputs": [],
   "source": [
    "## comes out in bytes instead of a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3d2671ed-cb5e-45fb-9aa2-8a668ffc0de2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(source).count('Soup')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5720ca1f-67bc-484f-a1e9-8612c6d7afc7",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.0 Transitional//EN\" \"http://www.w3.org/TR/REC-html40/transitional.dtd\">\n",
       "<html>\n",
       "<head>\n",
       "<meta content=\"text/html; charset=utf-8\" http-equiv=\"Content-Type\"/>\n",
       "<title>Beautiful Soup: We called him Tortoise because he taught us.</title>\n",
       "<link href=\"mailto:leonardr@segfault.org\" rev=\"made\"/>\n",
       "<link href=\"/nb/themes/Default/nb.css\" rel=\"stylesheet\" type=\"text/css\"/>\n",
       "<meta content=\"Beautiful Soup: a library designed for screen-scraping HTML and XML.\" name=\"Description\"/>\n",
       "<meta content=\"Markov Approximation 1.4 (module: leonardr)\" name=\"generator\"/>\n",
       "<meta content=\"Leonard Richardson\" name=\"author\"/>\n",
       "</head>\n",
       "<body alink=\"red\" bgcolor=\"white\" link=\"blue\" text=\"black\" vlink=\"660066\">\n",
       "<style>\n",
       "#tidelift { }\n",
       "\n",
       "#tidelift a {\n",
       " border: 1px solid #666666;\n",
       " margin-left: auto;\n",
       " padding: 10px;\n",
       " text-decoration: none;\n",
       "}\n",
       "\n",
       "#tidelift .cta {\n",
       " background: url(\"tidelift.svg\") no-repeat;\n",
       " padding-left: 30px;\n",
       "}\n",
       "</style>\n",
       "<img align=\"right\" src=\"10.1.jpg\" width=\"250\"/><br/>\n",
       "<p>[ <a href=\"#Download\">Download</a> | <a href=\"bs4/doc/\">Documentation</a> | <a href=\"#HallOfFame\">Hall of Fame</a> | <a href=\"enterprise.html\">For enterprise</a> | <a href=\"https://code.launchpad.net/beautifulsoup\">Source</a> | <a href=\"https://git.launchpad.net/beautifulsoup/tree/CHANGELOG\">Changelog</a> | <a href=\"https://groups.google.com/forum/?fromgroups#!forum/beautifulsoup\">Discussion group</a>  | <a href=\"zine/\">Zine</a> ]</p>\n",
       "<div align=\"center\">\n",
       "<a href=\"bs4/download/\"><h1>Beautiful Soup</h1></a>\n",
       "</div>\n",
       "<p>You didn't write that awful page. You're just trying to get some\n",
       "data out of it. Beautiful Soup is here to help. Since 2004, it's been\n",
       "saving programmers hours or days of work on quick-turnaround\n",
       "screen scraping projects.</p>\n",
       "<p>Beautiful Soup is a Python library designed for quick turnaround\n",
       "projects like screen-scraping. Three features make it powerful:\n",
       "\n",
       "</p><ol>\n",
       "<li>Beautiful Soup provides a few simple methods and Pythonic idioms\n",
       "for navigating, searching, and modifying a parse tree: a toolkit for\n",
       "dissecting a document and extracting what you need. It doesn't take\n",
       "much code to write an application\n",
       "\n",
       "</li><li>Beautiful Soup automatically converts incoming documents to\n",
       "Unicode and outgoing documents to UTF-8. You don't have to think\n",
       "about encodings, unless the document doesn't specify an encoding and\n",
       "Beautiful Soup can't detect one. Then you just have to specify the\n",
       "original encoding.\n",
       "\n",
       "</li><li>Beautiful Soup sits on top of popular Python parsers like <a href=\"http://lxml.de/\">lxml</a> and <a href=\"http://code.google.com/p/html5lib/\">html5lib</a>, allowing you\n",
       "to try out different parsing strategies or trade speed for\n",
       "flexibility.\n",
       "\n",
       "</li></ol>\n",
       "<p>Beautiful Soup parses anything you give it, and does the tree\n",
       "traversal stuff for you. You can tell it \"Find all the links\", or\n",
       "\"Find all the links of class <tt>externalLink</tt>\", or \"Find all the\n",
       "links whose urls match \"foo.com\", or \"Find the table heading that's\n",
       "got bold text, then give me that text.\"\n",
       "\n",
       "</p><p>Valuable data that was once locked up in poorly-designed websites\n",
       "is now within your reach. Projects that would have taken hours take\n",
       "only minutes with Beautiful Soup.\n",
       "\n",
       "</p><p>Interested? <a href=\"bs4/doc/\">Read more.</a>\n",
       "</p><h3>Getting and giving support</h3>\n",
       "<div align=\"center\" id=\"tidelift\">\n",
       "<a href=\"https://tidelift.com/subscription/pkg/pypi-beautifulsoup4?utm_source=pypi-beautifulsoup4&amp;utm_medium=referral&amp;utm_campaign=enterprise\" target=\"_blank\">\n",
       "<span class=\"cta\">\n",
       "  Beautiful Soup for enterprise available via Tidelift\n",
       " </span>\n",
       "</a>\n",
       "</div>\n",
       "<p>If you have questions, send them to <a href=\"https://groups.google.com/forum/?fromgroups#!forum/beautifulsoup\">the discussion\n",
       "group</a>. If you find a bug, <a href=\"https://bugs.launchpad.net/beautifulsoup/\">file it on Launchpad</a>. If it's a security vulnerability, report it confidentially through <a href=\"https://tidelift.com/security\">Tidelift</a>.</p>\n",
       "<p>If you use Beautiful Soup as part of your work, please consider a <a href=\"https://tidelift.com/subscription/pkg/pypi-beautifulsoup4?utm_source=pypi-beautifulsoup4&amp;utm_medium=referral&amp;utm_campaign=website\">Tidelift subscription</a>. This will support many of the free software projects your organization depends on, not just Beautiful Soup.\n",
       "\n",
       "\n",
       "</p><p>If Beautiful Soup is useful to you on a personal level, you might like to read <a href=\"zine/\"><i>Tool Safety</i></a>, a short zine I wrote about what I learned about software development from working on Beautiful Soup. Thanks!</p>\n",
       "<a name=\"Download\"><h2>Download Beautiful Soup</h2></a>\n",
       "<p>The current release is <a href=\"bs4/download/\">Beautiful Soup\n",
       "4.12.3</a> (January 17, 2024). You can install Beautiful Soup 4 with\n",
       "<code>pip install beautifulsoup4</code>.\n",
       "\n",
       "</p><p>In Debian and Ubuntu, Beautiful Soup is available as the\n",
       "<code>python3-bs4</code> package. In Fedora it's\n",
       "available as the <code>python3-beautifulsoup4</code> package.\n",
       "\n",
       "</p><p>Beautiful Soup is licensed under the MIT license, so you can also\n",
       "download the tarball, drop the <code>bs4/</code> directory into almost\n",
       "any Python application (or into your library path) and start using it\n",
       "immediately.\n",
       "\n",
       "</p><p>Beautiful Soup 4 is supported on Python versions 3.6 and\n",
       "greater. Support for Python 2 was discontinued on January 1, 2021—one\n",
       "year after the Python 2 sunsetting date.\n",
       "\n",
       "</p><h3>Beautiful Soup 3</h3>\n",
       "<p>Beautiful Soup 3 was the official release line of Beautiful Soup\n",
       "from May 2006 to March 2012. It does not support Python 3 and was\n",
       "discontinued or January 1, 2021—one year after the Python 2\n",
       "sunsetting date. If you have any active projects using Beautiful Soup\n",
       "3, you should migrate to Beautiful Soup 4 as part of your Python 3\n",
       "conversion.\n",
       "\n",
       "</p><p><a href=\"http://www.crummy.com/software/BeautifulSoup/bs3/documentation.html\">Here's\n",
       "the Beautiful Soup 3 documentation.</a>\n",
       "</p><p>The current and hopefully final release of Beautiful Soup 3 is <a href=\"download/3.x/BeautifulSoup-3.2.2.tar.gz\">3.2.2</a> (October 5,\n",
       "2019). It's the <code>BeautifulSoup</code> package on pip. It's also\n",
       "available as <code>python-beautifulsoup</code> in Debian and Ubuntu,\n",
       "and as <code>python-BeautifulSoup</code> in Fedora.\n",
       "\n",
       "</p><p>Once Beautiful Soup 3 is discontinued, these package names will be available for use by a more recent version of Beautiful Soup.\n",
       "\n",
       "</p><p>Beautiful Soup 3, like Beautiful Soup 4, is <a href=\"https://tidelift.com/subscription/pkg/pypi-beautifulsoup?utm_source=pypi-beautifulsoup&amp;utm_medium=referral&amp;utm_campaign=website\">supported through Tidelift</a>.</p>\n",
       "<a name=\"HallOfFame\"><h2>Hall of Fame</h2></a>\n",
       "<p>Over the years, Beautiful Soup has been used in hundreds of\n",
       "different projects. There's no way I can list them all, but I want to\n",
       "highlight a few high-profile projects. Beautiful Soup isn't what makes\n",
       "these projects interesting, but it did make their completion easier:\n",
       "\n",
       "</p><ul>\n",
       "<li><a href=\"http://www.nytimes.com/2007/10/25/arts/design/25vide.html\">\"Movable\n",
       " Type\"</a>, a work of digital art on display in the lobby of the New\n",
       " York Times building, uses Beautiful Soup to scrape news feeds.\n",
       "\n",
       "</li><li>Jiabao Lin's <a href=\"https://github.com/BlankerL/DXY-COVID-19-Crawler\">DXY-COVID-19-Crawler</a>\n",
       "uses Beautiful Soup to scrape a Chinese medical site for information\n",
       "about COVID-19, making it easier for researchers to track the spread\n",
       "of the virus. (Source: <a href=\"https://blog.tidelift.com/how-open-source-software-is-fighting-covid-19\">\"How open source software is fighting COVID-19\"</a>)\n",
       "\n",
       "</li><li>Reddit uses Beautiful Soup to <a href=\"https://github.com/reddit/reddit/blob/85f9cff3e2ab9bb8f19b96acd8da4ebacc079f04/r2/r2/lib/media.py\">parse\n",
       "a page that's been linked to and find a representative image</a>.\n",
       "\n",
       "</li><li>Alexander Harrowell uses Beautiful Soup to <a href=\"http://www.harrowell.org.uk/viktormap.html\">track the business\n",
       " activities</a> of an arms merchant.\n",
       "\n",
       "</li><li>The developers of Python itself used Beautiful Soup to <a href=\"http://svn.python.org/view/tracker/importer/\">migrate the Python\n",
       "bug tracker from Sourceforge to Roundup</a>.\n",
       "\n",
       "</li><li>The <a href=\"http://www2.ljworld.com/\">Lawrence Journal-World</a>\n",
       "uses Beautiful Soup to <a href=\"http://www.b-list.org/weblog/2010/nov/02/news-done-broke/\">gather\n",
       "statewide election results</a>.\n",
       "\n",
       "</li><li>The <a href=\"http://esrl.noaa.gov/gsd/fab/\">NOAA's Forecast\n",
       "Applications Branch</a> uses Beautiful Soup in <a href=\"http://laps.noaa.gov/topograbber/\">TopoGrabber</a>, a script for\n",
       "downloading \"high resolution USGS datasets.\"\n",
       "\n",
       "</li></ul>\n",
       "<p>If you've used Beautiful Soup in a project you'd like me to know\n",
       "about, please do send email to me or <a href=\"http://groups.google.com/group/beautifulsoup/\">the discussion\n",
       "group</a>.\n",
       "\n",
       "</p><h2>Development</h2>\n",
       "<p>Development happens at <a href=\"https://launchpad.net/beautifulsoup\">Launchpad</a>. You can <a href=\"https://code.launchpad.net/beautifulsoup/\">get the source\n",
       "code</a> or <a href=\"https://bugs.launchpad.net/beautifulsoup/\">file\n",
       "bugs</a>.</p><hr/><table><tr><td valign=\"top\">\n",
       "<p>This document is part of Crummy, the webspace of <a href=\"/self/\">Leonard Richardson</a> (<a href=\"/self/contact.html\">contact information</a>). It was last modified on Wednesday, January 17 2024, 16:54:42 Nowhere Standard Time and last built on Monday, March 04 2024, 03:00:01 Nowhere Standard Time.</p><p></p><table class=\"licenseText\"><tr><td><a href=\"http://creativecommons.org/licenses/by-sa/2.0/\"><img border=\"0\" src=\"/nb//resources/img/somerights20.jpg\"/></a></td><td valign=\"top\">Crummy is © 1996-2024 Leonard Richardson. Unless otherwise noted, all text licensed under a <a href=\"http://creativecommons.org/licenses/by-sa/2.0/\">Creative Commons License</a>.</td></tr></table><!--<rdf:RDF xmlns=\"http://web.resource.org/cc/\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\"><Work rdf:about=\"http://www.crummy.com/\"><dc:title>Crummy: The Site</dc:title><dc:rights><Agent><dc:title>Crummy: the Site</dc:title></Agent></dc:rights><dc:format>text/html</dc:format><license rdf:resource=http://creativecommons.org/licenses/by-sa/2.0//></Work><License rdf:about=\"http://creativecommons.org/licenses/by-sa/2.0/\"></License></rdf:RDF>--></td><td valign=\"top\"><p><b>Document tree:</b>\n",
       "</p><dl><dd><a href=\"http://www.crummy.com/\">http://www.crummy.com/</a><dl><dd><a href=\"http://www.crummy.com/software/\">software/</a><dl><dd><a href=\"http://www.crummy.com/software/BeautifulSoup/\">BeautifulSoup/</a></dd></dl>\n",
       "</dd></dl>\n",
       "</dd></dl>\n",
       "\n",
       "\n",
       "Site Search:\n",
       "\n",
       "<form action=\"/search/\" method=\"get\">\n",
       "<input maxlength=\"255\" name=\"q\" type=\"text\" value=\"\"/>\n",
       "</form>\n",
       "</td>\n",
       "</tr>\n",
       "</table>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup = BeautifulSoup(source)\n",
    "\n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cb5743bc-3be3-4b52-9caa-8dab4c5a5549",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.0 Transitional//EN\" \"http://www.w3.org/TR/REC-html40/transitional.dtd\">\\n<html>\\n <head>\\n  <meta content=\"text/html; charset=utf-8\" http-equiv=\"Content-Type\"/>\\n  <title>\\n   Beautiful Soup: We called him Tortoise because he taught us.\\n  </title>\\n  <link href=\"mailto:leonardr@segfault.org\" rev=\"made\"/>\\n  <link href=\"/nb/themes/Default/nb.css\" rel=\"stylesheet\" type=\"text/css\"/>\\n  <meta content=\"Beautiful Soup: a library designed for screen-scraping HTML and XML.\" name=\"Description\"/>\\n  <meta content=\"Markov Approximation 1.4 (module: leonardr)\" name=\"generator\"/>\\n  <meta content=\"Leonard Richardson\" name=\"author\"/>\\n </head>\\n <body alink=\"red\" bgcolor=\"white\" link=\"blue\" text=\"black\" vlink=\"660066\">\\n  <style>\\n   #tidelift { }\\n\\n#tidelift a {\\n border: 1px solid #666666;\\n margin-left: auto;\\n padding: 10px;\\n text-decoration: none;\\n}\\n\\n#tidelift .cta {\\n background: url(\"tidelift.svg\") no-repeat;\\n padding-left: 30px;\\n}\\n  </style>\\n  <img align=\"right\" src=\"10.1.jpg\" width=\"250\"/>\\n  <br/>\\n  <p>\\n   [\\n   <a href=\"#Download\">\\n    Download\\n   </a>\\n   |\\n   <a href=\"bs4/doc/\">\\n    Documentation\\n   </a>\\n   |\\n   <a href=\"#HallOfFame\">\\n    Hall of Fame\\n   </a>\\n   |\\n   <a href=\"enterprise.html\">\\n    For enterprise\\n   </a>\\n   |\\n   <a href=\"https://code.launchpad.net/beautifulsoup\">\\n    Source\\n   </a>\\n   |\\n   <a href=\"https://git.launchpad.net/beautifulsoup/tree/CHANGELOG\">\\n    Changelog\\n   </a>\\n   |\\n   <a href=\"https://groups.google.com/forum/?fromgroups#!forum/beautifulsoup\">\\n    Discussion group\\n   </a>\\n   |\\n   <a href=\"zine/\">\\n    Zine\\n   </a>\\n   ]\\n  </p>\\n  <div align=\"center\">\\n   <a href=\"bs4/download/\">\\n    <h1>\\n     Beautiful Soup\\n    </h1>\\n   </a>\\n  </div>\\n  <p>\\n   You didn\\'t write that awful page. You\\'re just trying to get some\\ndata out of it. Beautiful Soup is here to help. Since 2004, it\\'s been\\nsaving programmers hours or days of work on quick-turnaround\\nscreen scraping projects.\\n  </p>\\n  <p>\\n   Beautiful Soup is a Python library designed for quick turnaround\\nprojects like screen-scraping. Three features make it powerful:\\n  </p>\\n  <ol>\\n   <li>\\n    Beautiful Soup provides a few simple methods and Pythonic idioms\\nfor navigating, searching, and modifying a parse tree: a toolkit for\\ndissecting a document and extracting what you need. It doesn\\'t take\\nmuch code to write an application\\n   </li>\\n   <li>\\n    Beautiful Soup automatically converts incoming documents to\\nUnicode and outgoing documents to UTF-8. You don\\'t have to think\\nabout encodings, unless the document doesn\\'t specify an encoding and\\nBeautiful Soup can\\'t detect one. Then you just have to specify the\\noriginal encoding.\\n   </li>\\n   <li>\\n    Beautiful Soup sits on top of popular Python parsers like\\n    <a href=\"http://lxml.de/\">\\n     lxml\\n    </a>\\n    and\\n    <a href=\"http://code.google.com/p/html5lib/\">\\n     html5lib\\n    </a>\\n    , allowing you\\nto try out different parsing strategies or trade speed for\\nflexibility.\\n   </li>\\n  </ol>\\n  <p>\\n   Beautiful Soup parses anything you give it, and does the tree\\ntraversal stuff for you. You can tell it \"Find all the links\", or\\n\"Find all the links of class\\n   <tt>\\n    externalLink\\n   </tt>\\n   \", or \"Find all the\\nlinks whose urls match \"foo.com\", or \"Find the table heading that\\'s\\ngot bold text, then give me that text.\"\\n  </p>\\n  <p>\\n   Valuable data that was once locked up in poorly-designed websites\\nis now within your reach. Projects that would have taken hours take\\nonly minutes with Beautiful Soup.\\n  </p>\\n  <p>\\n   Interested?\\n   <a href=\"bs4/doc/\">\\n    Read more.\\n   </a>\\n  </p>\\n  <h3>\\n   Getting and giving support\\n  </h3>\\n  <div align=\"center\" id=\"tidelift\">\\n   <a href=\"https://tidelift.com/subscription/pkg/pypi-beautifulsoup4?utm_source=pypi-beautifulsoup4&amp;utm_medium=referral&amp;utm_campaign=enterprise\" target=\"_blank\">\\n    <span class=\"cta\">\\n     Beautiful Soup for enterprise available via Tidelift\\n    </span>\\n   </a>\\n  </div>\\n  <p>\\n   If you have questions, send them to\\n   <a href=\"https://groups.google.com/forum/?fromgroups#!forum/beautifulsoup\">\\n    the discussion\\ngroup\\n   </a>\\n   . If you find a bug,\\n   <a href=\"https://bugs.launchpad.net/beautifulsoup/\">\\n    file it on Launchpad\\n   </a>\\n   . If it\\'s a security vulnerability, report it confidentially through\\n   <a href=\"https://tidelift.com/security\">\\n    Tidelift\\n   </a>\\n   .\\n  </p>\\n  <p>\\n   If you use Beautiful Soup as part of your work, please consider a\\n   <a href=\"https://tidelift.com/subscription/pkg/pypi-beautifulsoup4?utm_source=pypi-beautifulsoup4&amp;utm_medium=referral&amp;utm_campaign=website\">\\n    Tidelift subscription\\n   </a>\\n   . This will support many of the free software projects your organization depends on, not just Beautiful Soup.\\n  </p>\\n  <p>\\n   If Beautiful Soup is useful to you on a personal level, you might like to read\\n   <a href=\"zine/\">\\n    <i>\\n     Tool Safety\\n    </i>\\n   </a>\\n   , a short zine I wrote about what I learned about software development from working on Beautiful Soup. Thanks!\\n  </p>\\n  <a name=\"Download\">\\n   <h2>\\n    Download Beautiful Soup\\n   </h2>\\n  </a>\\n  <p>\\n   The current release is\\n   <a href=\"bs4/download/\">\\n    Beautiful Soup\\n4.12.3\\n   </a>\\n   (January 17, 2024). You can install Beautiful Soup 4 with\\n   <code>\\n    pip install beautifulsoup4\\n   </code>\\n   .\\n  </p>\\n  <p>\\n   In Debian and Ubuntu, Beautiful Soup is available as the\\n   <code>\\n    python3-bs4\\n   </code>\\n   package. In Fedora it\\'s\\navailable as the\\n   <code>\\n    python3-beautifulsoup4\\n   </code>\\n   package.\\n  </p>\\n  <p>\\n   Beautiful Soup is licensed under the MIT license, so you can also\\ndownload the tarball, drop the\\n   <code>\\n    bs4/\\n   </code>\\n   directory into almost\\nany Python application (or into your library path) and start using it\\nimmediately.\\n  </p>\\n  <p>\\n   Beautiful Soup 4 is supported on Python versions 3.6 and\\ngreater. Support for Python 2 was discontinued on January 1, 2021—one\\nyear after the Python 2 sunsetting date.\\n  </p>\\n  <h3>\\n   Beautiful Soup 3\\n  </h3>\\n  <p>\\n   Beautiful Soup 3 was the official release line of Beautiful Soup\\nfrom May 2006 to March 2012. It does not support Python 3 and was\\ndiscontinued or January 1, 2021—one year after the Python 2\\nsunsetting date. If you have any active projects using Beautiful Soup\\n3, you should migrate to Beautiful Soup 4 as part of your Python 3\\nconversion.\\n  </p>\\n  <p>\\n   <a href=\"http://www.crummy.com/software/BeautifulSoup/bs3/documentation.html\">\\n    Here\\'s\\nthe Beautiful Soup 3 documentation.\\n   </a>\\n  </p>\\n  <p>\\n   The current and hopefully final release of Beautiful Soup 3 is\\n   <a href=\"download/3.x/BeautifulSoup-3.2.2.tar.gz\">\\n    3.2.2\\n   </a>\\n   (October 5,\\n2019). It\\'s the\\n   <code>\\n    BeautifulSoup\\n   </code>\\n   package on pip. It\\'s also\\navailable as\\n   <code>\\n    python-beautifulsoup\\n   </code>\\n   in Debian and Ubuntu,\\nand as\\n   <code>\\n    python-BeautifulSoup\\n   </code>\\n   in Fedora.\\n  </p>\\n  <p>\\n   Once Beautiful Soup 3 is discontinued, these package names will be available for use by a more recent version of Beautiful Soup.\\n  </p>\\n  <p>\\n   Beautiful Soup 3, like Beautiful Soup 4, is\\n   <a href=\"https://tidelift.com/subscription/pkg/pypi-beautifulsoup?utm_source=pypi-beautifulsoup&amp;utm_medium=referral&amp;utm_campaign=website\">\\n    supported through Tidelift\\n   </a>\\n   .\\n  </p>\\n  <a name=\"HallOfFame\">\\n   <h2>\\n    Hall of Fame\\n   </h2>\\n  </a>\\n  <p>\\n   Over the years, Beautiful Soup has been used in hundreds of\\ndifferent projects. There\\'s no way I can list them all, but I want to\\nhighlight a few high-profile projects. Beautiful Soup isn\\'t what makes\\nthese projects interesting, but it did make their completion easier:\\n  </p>\\n  <ul>\\n   <li>\\n    <a href=\"http://www.nytimes.com/2007/10/25/arts/design/25vide.html\">\\n     \"Movable\\n Type\"\\n    </a>\\n    , a work of digital art on display in the lobby of the New\\n York Times building, uses Beautiful Soup to scrape news feeds.\\n   </li>\\n   <li>\\n    Jiabao Lin\\'s\\n    <a href=\"https://github.com/BlankerL/DXY-COVID-19-Crawler\">\\n     DXY-COVID-19-Crawler\\n    </a>\\n    uses Beautiful Soup to scrape a Chinese medical site for information\\nabout COVID-19, making it easier for researchers to track the spread\\nof the virus. (Source:\\n    <a href=\"https://blog.tidelift.com/how-open-source-software-is-fighting-covid-19\">\\n     \"How open source software is fighting COVID-19\"\\n    </a>\\n    )\\n   </li>\\n   <li>\\n    Reddit uses Beautiful Soup to\\n    <a href=\"https://github.com/reddit/reddit/blob/85f9cff3e2ab9bb8f19b96acd8da4ebacc079f04/r2/r2/lib/media.py\">\\n     parse\\na page that\\'s been linked to and find a representative image\\n    </a>\\n    .\\n   </li>\\n   <li>\\n    Alexander Harrowell uses Beautiful Soup to\\n    <a href=\"http://www.harrowell.org.uk/viktormap.html\">\\n     track the business\\n activities\\n    </a>\\n    of an arms merchant.\\n   </li>\\n   <li>\\n    The developers of Python itself used Beautiful Soup to\\n    <a href=\"http://svn.python.org/view/tracker/importer/\">\\n     migrate the Python\\nbug tracker from Sourceforge to Roundup\\n    </a>\\n    .\\n   </li>\\n   <li>\\n    The\\n    <a href=\"http://www2.ljworld.com/\">\\n     Lawrence Journal-World\\n    </a>\\n    uses Beautiful Soup to\\n    <a href=\"http://www.b-list.org/weblog/2010/nov/02/news-done-broke/\">\\n     gather\\nstatewide election results\\n    </a>\\n    .\\n   </li>\\n   <li>\\n    The\\n    <a href=\"http://esrl.noaa.gov/gsd/fab/\">\\n     NOAA\\'s Forecast\\nApplications Branch\\n    </a>\\n    uses Beautiful Soup in\\n    <a href=\"http://laps.noaa.gov/topograbber/\">\\n     TopoGrabber\\n    </a>\\n    , a script for\\ndownloading \"high resolution USGS datasets.\"\\n   </li>\\n  </ul>\\n  <p>\\n   If you\\'ve used Beautiful Soup in a project you\\'d like me to know\\nabout, please do send email to me or\\n   <a href=\"http://groups.google.com/group/beautifulsoup/\">\\n    the discussion\\ngroup\\n   </a>\\n   .\\n  </p>\\n  <h2>\\n   Development\\n  </h2>\\n  <p>\\n   Development happens at\\n   <a href=\"https://launchpad.net/beautifulsoup\">\\n    Launchpad\\n   </a>\\n   . You can\\n   <a href=\"https://code.launchpad.net/beautifulsoup/\">\\n    get the source\\ncode\\n   </a>\\n   or\\n   <a href=\"https://bugs.launchpad.net/beautifulsoup/\">\\n    file\\nbugs\\n   </a>\\n   .\\n  </p>\\n  <hr/>\\n  <table>\\n   <tr>\\n    <td valign=\"top\">\\n     <p>\\n      This document is part of Crummy, the webspace of\\n      <a href=\"/self/\">\\n       Leonard Richardson\\n      </a>\\n      (\\n      <a href=\"/self/contact.html\">\\n       contact information\\n      </a>\\n      ). It was last modified on Wednesday, January 17 2024, 16:54:42 Nowhere Standard Time and last built on Monday, March 04 2024, 03:00:01 Nowhere Standard Time.\\n     </p>\\n     <p>\\n     </p>\\n     <table class=\"licenseText\">\\n      <tr>\\n       <td>\\n        <a href=\"http://creativecommons.org/licenses/by-sa/2.0/\">\\n         <img border=\"0\" src=\"/nb//resources/img/somerights20.jpg\"/>\\n        </a>\\n       </td>\\n       <td valign=\"top\">\\n        Crummy is © 1996-2024 Leonard Richardson. Unless otherwise noted, all text licensed under a\\n        <a href=\"http://creativecommons.org/licenses/by-sa/2.0/\">\\n         Creative Commons License\\n        </a>\\n        .\\n       </td>\\n      </tr>\\n     </table>\\n     <!--<rdf:RDF xmlns=\"http://web.resource.org/cc/\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\"><Work rdf:about=\"http://www.crummy.com/\"><dc:title>Crummy: The Site</dc:title><dc:rights><Agent><dc:title>Crummy: the Site</dc:title></Agent></dc:rights><dc:format>text/html</dc:format><license rdf:resource=http://creativecommons.org/licenses/by-sa/2.0//></Work><License rdf:about=\"http://creativecommons.org/licenses/by-sa/2.0/\"></License></rdf:RDF>-->\\n    </td>\\n    <td valign=\"top\">\\n     <p>\\n      <b>\\n       Document tree:\\n      </b>\\n     </p>\\n     <dl>\\n      <dd>\\n       <a href=\"http://www.crummy.com/\">\\n        http://www.crummy.com/\\n       </a>\\n       <dl>\\n        <dd>\\n         <a href=\"http://www.crummy.com/software/\">\\n          software/\\n         </a>\\n         <dl>\\n          <dd>\\n           <a href=\"http://www.crummy.com/software/BeautifulSoup/\">\\n            BeautifulSoup/\\n           </a>\\n          </dd>\\n         </dl>\\n        </dd>\\n       </dl>\\n      </dd>\\n     </dl>\\n     Site Search:\\n     <form action=\"/search/\" method=\"get\">\\n      <input maxlength=\"255\" name=\"q\" type=\"text\" value=\"\"/>\\n     </form>\\n    </td>\\n   </tr>\\n  </table>\\n </body>\\n</html>\\n'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.prettify()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e38faa-6b4e-4e5b-8f70-4e335450c294",
   "metadata": {},
   "source": [
    "'<a href=' is a link to click and the underlined linked will have as name what you put after the > instead of the https:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d8ed2218-35ab-4133-82aa-e47566f1611a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['#Download',\n",
       " 'bs4/doc/',\n",
       " '#HallOfFame',\n",
       " 'enterprise.html',\n",
       " 'https://code.launchpad.net/beautifulsoup',\n",
       " 'https://git.launchpad.net/beautifulsoup/tree/CHANGELOG',\n",
       " 'https://groups.google.com/forum/?fromgroups#!forum/beautifulsoup',\n",
       " 'zine/',\n",
       " 'bs4/download/',\n",
       " 'http://lxml.de/']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "link_list = [l.get('href') for l in soup.findAll('a')]\n",
    "link_list[0:10]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5f73e08b-b9a7-4447-bd7a-c9949f6764a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Filter all external links\n",
    "external_links = list()\n",
    "\n",
    "for l in link_list:\n",
    "    if l == 'http' and l is not None:\n",
    "        external_links.append(l)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9820ebdf-d0ca-481f-bd49-4f6375b606a2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<body><h3> Test </h3><p>Hello world!</p></body>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# redifining `s` without any line breaks\n",
    "s = \"\"\"<!DOCTYPE html><html><head><title>This is a title</title></head><body><h3> Test </h3><p>Hello world!</p></body></html>\"\"\"\n",
    "## get bs4 object\n",
    "tree = BeautifulSoup(s)\n",
    "\n",
    "## get html root node\n",
    "root_node = tree.html\n",
    "\n",
    "## get head from root using contents\n",
    "head = root_node.contents[0]\n",
    "\n",
    "## get body from root\n",
    "body = root_node.contents[1]\n",
    "\n",
    "## could directly access body\n",
    "tree.body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e6e7a698-3091-4967-bd79-79378aa26504",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<!DOCTYPE html>\n",
       "<html><head><title>This is a title</title></head><body><h3> Test </h3><p>Hello world!</p></body></html>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3aefc1d6-7012-4610-b4c3-413ba640e2c8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<html><head><title>This is a title</title></head><body><h3> Test </h3><p>Hello world!</p></body></html>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "64eec702-715d-4b54-bc68-1d2a23b5c85a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<head><title>This is a title</title></head>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "26cac928-1eb2-4dc6-bac5-a38f43a1367c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<body><h3> Test </h3><p>Hello world!</p></body>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "877661fa-31d3-4987-ac04-99ae1d5e4cd7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<body><h3> Test </h3><p>Hello world!</p></body>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.body"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469a8609-b5ae-40be-889f-d4778b5109da",
   "metadata": {},
   "source": [
    "## What skills are on demand for Data Scientists?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "88aeb38f-0815-41bf-9809-37857c58072c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "url = 'http://www.indeed.com/jobs?q=data+scientist&l='"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2e7f4a9e-9f63-4f7a-b1a9-c1b357e130d6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "HTTP Error 403: Forbidden",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[66], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m source \u001b[38;5;241m=\u001b[39m urllib2\u001b[38;5;241m.\u001b[39murlopen(url)\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m      2\u001b[0m bs_tree \u001b[38;5;241m=\u001b[39m BeautifulSoup(source)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/urllib/request.py:216\u001b[0m, in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    215\u001b[0m     opener \u001b[38;5;241m=\u001b[39m _opener\n\u001b[0;32m--> 216\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m opener\u001b[38;5;241m.\u001b[39mopen(url, data, timeout)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/urllib/request.py:525\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    523\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m processor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_response\u001b[38;5;241m.\u001b[39mget(protocol, []):\n\u001b[1;32m    524\u001b[0m     meth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(processor, meth_name)\n\u001b[0;32m--> 525\u001b[0m     response \u001b[38;5;241m=\u001b[39m meth(req, response)\n\u001b[1;32m    527\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/urllib/request.py:634\u001b[0m, in \u001b[0;36mHTTPErrorProcessor.http_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;66;03m# According to RFC 2616, \"2xx\" code indicates that the client's\u001b[39;00m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;66;03m# request was successfully received, understood, and accepted.\u001b[39;00m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m code \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m):\n\u001b[0;32m--> 634\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparent\u001b[38;5;241m.\u001b[39merror(\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttp\u001b[39m\u001b[38;5;124m'\u001b[39m, request, response, code, msg, hdrs)\n\u001b[1;32m    637\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/urllib/request.py:563\u001b[0m, in \u001b[0;36mOpenerDirector.error\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    561\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_err:\n\u001b[1;32m    562\u001b[0m     args \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mdict\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttp_error_default\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m+\u001b[39m orig_args\n\u001b[0;32m--> 563\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_chain(\u001b[38;5;241m*\u001b[39margs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/urllib/request.py:496\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[1;32m    495\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[0;32m--> 496\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m    497\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    498\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/urllib/request.py:643\u001b[0m, in \u001b[0;36mHTTPDefaultErrorHandler.http_error_default\u001b[0;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[1;32m    642\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhttp_error_default\u001b[39m(\u001b[38;5;28mself\u001b[39m, req, fp, code, msg, hdrs):\n\u001b[0;32m--> 643\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(req\u001b[38;5;241m.\u001b[39mfull_url, code, msg, hdrs, fp)\n",
      "\u001b[0;31mHTTPError\u001b[0m: HTTP Error 403: Forbidden"
     ]
    }
   ],
   "source": [
    "source = urllib2.urlopen(url).read()\n",
    "bs_tree = BeautifulSoup(source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ca0f0266-150d-4024-a9a8-3cf5f8cd5a08",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "job_postings = bs_tree.find(id = 'searchCount')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "84c683b7-cadd-4da8-b92b-e2bdb5b8fd6d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "job_postings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3f61801b-efca-4a9a-bf40-89f1b475ead0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.0 Transitional//EN\" \"http://www.w3.org/TR/REC-html40/transitional.dtd\">\n",
       "<html>\n",
       "<head>\n",
       "<meta content=\"text/html; charset=utf-8\" http-equiv=\"Content-Type\"/>\n",
       "<title>Beautiful Soup: We called him Tortoise because he taught us.</title>\n",
       "<link href=\"mailto:leonardr@segfault.org\" rev=\"made\"/>\n",
       "<link href=\"/nb/themes/Default/nb.css\" rel=\"stylesheet\" type=\"text/css\"/>\n",
       "<meta content=\"Beautiful Soup: a library designed for screen-scraping HTML and XML.\" name=\"Description\"/>\n",
       "<meta content=\"Markov Approximation 1.4 (module: leonardr)\" name=\"generator\"/>\n",
       "<meta content=\"Leonard Richardson\" name=\"author\"/>\n",
       "</head>\n",
       "<body alink=\"red\" bgcolor=\"white\" link=\"blue\" text=\"black\" vlink=\"660066\">\n",
       "<style>\n",
       "#tidelift { }\n",
       "\n",
       "#tidelift a {\n",
       " border: 1px solid #666666;\n",
       " margin-left: auto;\n",
       " padding: 10px;\n",
       " text-decoration: none;\n",
       "}\n",
       "\n",
       "#tidelift .cta {\n",
       " background: url(\"tidelift.svg\") no-repeat;\n",
       " padding-left: 30px;\n",
       "}\n",
       "</style>\n",
       "<img align=\"right\" src=\"10.1.jpg\" width=\"250\"/><br/>\n",
       "<p>[ <a href=\"#Download\">Download</a> | <a href=\"bs4/doc/\">Documentation</a> | <a href=\"#HallOfFame\">Hall of Fame</a> | <a href=\"enterprise.html\">For enterprise</a> | <a href=\"https://code.launchpad.net/beautifulsoup\">Source</a> | <a href=\"https://git.launchpad.net/beautifulsoup/tree/CHANGELOG\">Changelog</a> | <a href=\"https://groups.google.com/forum/?fromgroups#!forum/beautifulsoup\">Discussion group</a>  | <a href=\"zine/\">Zine</a> ]</p>\n",
       "<div align=\"center\">\n",
       "<a href=\"bs4/download/\"><h1>Beautiful Soup</h1></a>\n",
       "</div>\n",
       "<p>You didn't write that awful page. You're just trying to get some\n",
       "data out of it. Beautiful Soup is here to help. Since 2004, it's been\n",
       "saving programmers hours or days of work on quick-turnaround\n",
       "screen scraping projects.</p>\n",
       "<p>Beautiful Soup is a Python library designed for quick turnaround\n",
       "projects like screen-scraping. Three features make it powerful:\n",
       "\n",
       "</p><ol>\n",
       "<li>Beautiful Soup provides a few simple methods and Pythonic idioms\n",
       "for navigating, searching, and modifying a parse tree: a toolkit for\n",
       "dissecting a document and extracting what you need. It doesn't take\n",
       "much code to write an application\n",
       "\n",
       "</li><li>Beautiful Soup automatically converts incoming documents to\n",
       "Unicode and outgoing documents to UTF-8. You don't have to think\n",
       "about encodings, unless the document doesn't specify an encoding and\n",
       "Beautiful Soup can't detect one. Then you just have to specify the\n",
       "original encoding.\n",
       "\n",
       "</li><li>Beautiful Soup sits on top of popular Python parsers like <a href=\"http://lxml.de/\">lxml</a> and <a href=\"http://code.google.com/p/html5lib/\">html5lib</a>, allowing you\n",
       "to try out different parsing strategies or trade speed for\n",
       "flexibility.\n",
       "\n",
       "</li></ol>\n",
       "<p>Beautiful Soup parses anything you give it, and does the tree\n",
       "traversal stuff for you. You can tell it \"Find all the links\", or\n",
       "\"Find all the links of class <tt>externalLink</tt>\", or \"Find all the\n",
       "links whose urls match \"foo.com\", or \"Find the table heading that's\n",
       "got bold text, then give me that text.\"\n",
       "\n",
       "</p><p>Valuable data that was once locked up in poorly-designed websites\n",
       "is now within your reach. Projects that would have taken hours take\n",
       "only minutes with Beautiful Soup.\n",
       "\n",
       "</p><p>Interested? <a href=\"bs4/doc/\">Read more.</a>\n",
       "</p><h3>Getting and giving support</h3>\n",
       "<div align=\"center\" id=\"tidelift\">\n",
       "<a href=\"https://tidelift.com/subscription/pkg/pypi-beautifulsoup4?utm_source=pypi-beautifulsoup4&amp;utm_medium=referral&amp;utm_campaign=enterprise\" target=\"_blank\">\n",
       "<span class=\"cta\">\n",
       "  Beautiful Soup for enterprise available via Tidelift\n",
       " </span>\n",
       "</a>\n",
       "</div>\n",
       "<p>If you have questions, send them to <a href=\"https://groups.google.com/forum/?fromgroups#!forum/beautifulsoup\">the discussion\n",
       "group</a>. If you find a bug, <a href=\"https://bugs.launchpad.net/beautifulsoup/\">file it on Launchpad</a>. If it's a security vulnerability, report it confidentially through <a href=\"https://tidelift.com/security\">Tidelift</a>.</p>\n",
       "<p>If you use Beautiful Soup as part of your work, please consider a <a href=\"https://tidelift.com/subscription/pkg/pypi-beautifulsoup4?utm_source=pypi-beautifulsoup4&amp;utm_medium=referral&amp;utm_campaign=website\">Tidelift subscription</a>. This will support many of the free software projects your organization depends on, not just Beautiful Soup.\n",
       "\n",
       "\n",
       "</p><p>If Beautiful Soup is useful to you on a personal level, you might like to read <a href=\"zine/\"><i>Tool Safety</i></a>, a short zine I wrote about what I learned about software development from working on Beautiful Soup. Thanks!</p>\n",
       "<a name=\"Download\"><h2>Download Beautiful Soup</h2></a>\n",
       "<p>The current release is <a href=\"bs4/download/\">Beautiful Soup\n",
       "4.12.3</a> (January 17, 2024). You can install Beautiful Soup 4 with\n",
       "<code>pip install beautifulsoup4</code>.\n",
       "\n",
       "</p><p>In Debian and Ubuntu, Beautiful Soup is available as the\n",
       "<code>python3-bs4</code> package. In Fedora it's\n",
       "available as the <code>python3-beautifulsoup4</code> package.\n",
       "\n",
       "</p><p>Beautiful Soup is licensed under the MIT license, so you can also\n",
       "download the tarball, drop the <code>bs4/</code> directory into almost\n",
       "any Python application (or into your library path) and start using it\n",
       "immediately.\n",
       "\n",
       "</p><p>Beautiful Soup 4 is supported on Python versions 3.6 and\n",
       "greater. Support for Python 2 was discontinued on January 1, 2021—one\n",
       "year after the Python 2 sunsetting date.\n",
       "\n",
       "</p><h3>Beautiful Soup 3</h3>\n",
       "<p>Beautiful Soup 3 was the official release line of Beautiful Soup\n",
       "from May 2006 to March 2012. It does not support Python 3 and was\n",
       "discontinued or January 1, 2021—one year after the Python 2\n",
       "sunsetting date. If you have any active projects using Beautiful Soup\n",
       "3, you should migrate to Beautiful Soup 4 as part of your Python 3\n",
       "conversion.\n",
       "\n",
       "</p><p><a href=\"http://www.crummy.com/software/BeautifulSoup/bs3/documentation.html\">Here's\n",
       "the Beautiful Soup 3 documentation.</a>\n",
       "</p><p>The current and hopefully final release of Beautiful Soup 3 is <a href=\"download/3.x/BeautifulSoup-3.2.2.tar.gz\">3.2.2</a> (October 5,\n",
       "2019). It's the <code>BeautifulSoup</code> package on pip. It's also\n",
       "available as <code>python-beautifulsoup</code> in Debian and Ubuntu,\n",
       "and as <code>python-BeautifulSoup</code> in Fedora.\n",
       "\n",
       "</p><p>Once Beautiful Soup 3 is discontinued, these package names will be available for use by a more recent version of Beautiful Soup.\n",
       "\n",
       "</p><p>Beautiful Soup 3, like Beautiful Soup 4, is <a href=\"https://tidelift.com/subscription/pkg/pypi-beautifulsoup?utm_source=pypi-beautifulsoup&amp;utm_medium=referral&amp;utm_campaign=website\">supported through Tidelift</a>.</p>\n",
       "<a name=\"HallOfFame\"><h2>Hall of Fame</h2></a>\n",
       "<p>Over the years, Beautiful Soup has been used in hundreds of\n",
       "different projects. There's no way I can list them all, but I want to\n",
       "highlight a few high-profile projects. Beautiful Soup isn't what makes\n",
       "these projects interesting, but it did make their completion easier:\n",
       "\n",
       "</p><ul>\n",
       "<li><a href=\"http://www.nytimes.com/2007/10/25/arts/design/25vide.html\">\"Movable\n",
       " Type\"</a>, a work of digital art on display in the lobby of the New\n",
       " York Times building, uses Beautiful Soup to scrape news feeds.\n",
       "\n",
       "</li><li>Jiabao Lin's <a href=\"https://github.com/BlankerL/DXY-COVID-19-Crawler\">DXY-COVID-19-Crawler</a>\n",
       "uses Beautiful Soup to scrape a Chinese medical site for information\n",
       "about COVID-19, making it easier for researchers to track the spread\n",
       "of the virus. (Source: <a href=\"https://blog.tidelift.com/how-open-source-software-is-fighting-covid-19\">\"How open source software is fighting COVID-19\"</a>)\n",
       "\n",
       "</li><li>Reddit uses Beautiful Soup to <a href=\"https://github.com/reddit/reddit/blob/85f9cff3e2ab9bb8f19b96acd8da4ebacc079f04/r2/r2/lib/media.py\">parse\n",
       "a page that's been linked to and find a representative image</a>.\n",
       "\n",
       "</li><li>Alexander Harrowell uses Beautiful Soup to <a href=\"http://www.harrowell.org.uk/viktormap.html\">track the business\n",
       " activities</a> of an arms merchant.\n",
       "\n",
       "</li><li>The developers of Python itself used Beautiful Soup to <a href=\"http://svn.python.org/view/tracker/importer/\">migrate the Python\n",
       "bug tracker from Sourceforge to Roundup</a>.\n",
       "\n",
       "</li><li>The <a href=\"http://www2.ljworld.com/\">Lawrence Journal-World</a>\n",
       "uses Beautiful Soup to <a href=\"http://www.b-list.org/weblog/2010/nov/02/news-done-broke/\">gather\n",
       "statewide election results</a>.\n",
       "\n",
       "</li><li>The <a href=\"http://esrl.noaa.gov/gsd/fab/\">NOAA's Forecast\n",
       "Applications Branch</a> uses Beautiful Soup in <a href=\"http://laps.noaa.gov/topograbber/\">TopoGrabber</a>, a script for\n",
       "downloading \"high resolution USGS datasets.\"\n",
       "\n",
       "</li></ul>\n",
       "<p>If you've used Beautiful Soup in a project you'd like me to know\n",
       "about, please do send email to me or <a href=\"http://groups.google.com/group/beautifulsoup/\">the discussion\n",
       "group</a>.\n",
       "\n",
       "</p><h2>Development</h2>\n",
       "<p>Development happens at <a href=\"https://launchpad.net/beautifulsoup\">Launchpad</a>. You can <a href=\"https://code.launchpad.net/beautifulsoup/\">get the source\n",
       "code</a> or <a href=\"https://bugs.launchpad.net/beautifulsoup/\">file\n",
       "bugs</a>.</p><hr/><table><tr><td valign=\"top\">\n",
       "<p>This document is part of Crummy, the webspace of <a href=\"/self/\">Leonard Richardson</a> (<a href=\"/self/contact.html\">contact information</a>). It was last modified on Wednesday, January 17 2024, 16:54:42 Nowhere Standard Time and last built on Monday, March 04 2024, 04:00:01 Nowhere Standard Time.</p><p></p><table class=\"licenseText\"><tr><td><a href=\"http://creativecommons.org/licenses/by-sa/2.0/\"><img border=\"0\" src=\"/nb//resources/img/somerights20.jpg\"/></a></td><td valign=\"top\">Crummy is © 1996-2024 Leonard Richardson. Unless otherwise noted, all text licensed under a <a href=\"http://creativecommons.org/licenses/by-sa/2.0/\">Creative Commons License</a>.</td></tr></table><!--<rdf:RDF xmlns=\"http://web.resource.org/cc/\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\"><Work rdf:about=\"http://www.crummy.com/\"><dc:title>Crummy: The Site</dc:title><dc:rights><Agent><dc:title>Crummy: the Site</dc:title></Agent></dc:rights><dc:format>text/html</dc:format><license rdf:resource=http://creativecommons.org/licenses/by-sa/2.0//></Work><License rdf:about=\"http://creativecommons.org/licenses/by-sa/2.0/\"></License></rdf:RDF>--></td><td valign=\"top\"><p><b>Document tree:</b>\n",
       "</p><dl><dd><a href=\"http://www.crummy.com/\">http://www.crummy.com/</a><dl><dd><a href=\"http://www.crummy.com/software/\">software/</a><dl><dd><a href=\"http://www.crummy.com/software/BeautifulSoup/\">BeautifulSoup/</a></dd></dl>\n",
       "</dd></dl>\n",
       "</dd></dl>\n",
       "\n",
       "\n",
       "Site Search:\n",
       "\n",
       "<form action=\"/search/\" method=\"get\">\n",
       "<input maxlength=\"255\" name=\"q\" type=\"text\" value=\"\"/>\n",
       "</form>\n",
       "</td>\n",
       "</tr>\n",
       "</table>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs_tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5bbf5f8-4c9f-4f65-b0ef-8b7ab82d9775",
   "metadata": {},
   "source": [
    "## Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5941b5a6-5400-476c-a276-677904fd586a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is my pickled object:\n",
      "b'\\x80\\x04\\x95!\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x8c\\x08__main__\\x94\\x8c\\rexample_class\\x94\\x93\\x94)\\x81\\x94.'\n",
      "\n",
      "This is a_dict of the unpickled object:\n",
      "{'first': 'a', 'second': 2, 'third': [1, 2, 3]}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# pickling.py\n",
    "import pickle\n",
    "\n",
    "class example_class:\n",
    "    a_number = 35\n",
    "    a_string = \"hey\"\n",
    "    a_list = [1, 2, 3]\n",
    "    a_dict = {\"first\": \"a\", \"second\": 2, \"third\": [1, 2, 3]}\n",
    "    a_tuple = (22, 23)\n",
    "\n",
    "my_object = example_class()\n",
    "\n",
    "my_pickled_object = pickle.dumps(my_object)  # Pickling the object\n",
    "print(f\"This is my pickled object:\\n{my_pickled_object}\\n\")\n",
    "\n",
    "my_object.a_dict = None\n",
    "\n",
    "my_unpickled_object = pickle.loads(my_pickled_object)  # Unpickling the object\n",
    "print(\n",
    "    f\"This is a_dict of the unpickled object:\\n{my_unpickled_object.a_dict}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b553e95-5e81-4823-8634-9e37b508d934",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
